{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjJn2R-Ft8Gi"
   },
   "source": [
    "For this homework, make sure that you format your notbook nicely and cite all sources in the appropriate sections. Programmatically generate or embed any figures or graphs that you need.\n",
    "\n",
    "Names: __YOUR NAMES HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzwlPkjgt8Gq"
   },
   "source": [
    "Step 1: Train your own word embeddings\n",
    "--------------------------------\n",
    "\n",
    "(describe the provided dataset that you have chosen here)\n",
    "\n",
    "Describe what data set you have chosen to compare and contrast with the your chosen provided dataset. Make sure to describe where it comes from and it's general properties.\n",
    "\n",
    "(describe your dataset here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T03:27:00.340250Z",
     "start_time": "2020-10-24T03:26:59.570883Z"
    },
    "id": "uQLg8dGdt8Gr"
   },
   "outputs": [],
   "source": [
    "# import your libraries here\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj0A0mCkt8Gt"
   },
   "source": [
    "### a) Train embeddings on GIVEN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:39:25.438770Z",
     "start_time": "2020-10-24T04:39:24.888507Z"
    },
    "id": "x2IJbX_Mt8Gu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "0      id26305  This process, however, afforded me no means of...    EAP\n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
       "...        ...                                                ...    ...\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to train your word embeddings\n",
    "\n",
    "SPOOKY_AUTHOR_TEXT = \"spooky-author-identification/train.csv\"\n",
    "\n",
    "# Read the file and prepare the training data \n",
    "# so that it is in the following format\n",
    "spooky_df = pd.read_csv(SPOOKY_AUTHOR_TEXT)\n",
    "\n",
    "# data = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "# \t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "# \t\t\t['yet', 'another', 'sentence'],\n",
    "# \t\t\t['one', 'more', 'sentence'],\n",
    "# \t\t\t['and', 'the', 'final', 'sentence']]\n",
    "\n",
    "spooky_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:39:38.482701Z",
     "start_time": "2020-10-24T04:39:28.044970Z"
    },
    "id": "Od_L53GEt8Gv"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# make all the text lowercase\n",
    "spooky_df.text = spooky_df.text.str.lower()\n",
    "\n",
    "# save the data as a list of tokenized sentences\n",
    "data = spooky_df.text.apply(nltk.word_tokenize).tolist()\n",
    "\n",
    "# The dimension of word embedding. \n",
    "# This variable will be used throughout the program\n",
    "# you may vary this as you desire\n",
    "EMBEDDINGS_SIZE = 200\n",
    "\n",
    "# Train the Word2Vec model from Gensim. \n",
    "# Below are the hyperparameters that are most relevant. \n",
    "# But feel free to explore other \n",
    "# options too:\n",
    "sg = 1\n",
    "window = 5\n",
    "vector_size = EMBEDDINGS_SIZE\n",
    "min_count = 1\n",
    "\n",
    "model_spooky = Word2Vec(sentences=data, vector_size=vector_size, window=window, min_count=min_count, sg=sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:39:43.448249Z",
     "start_time": "2020-10-24T04:39:43.444835Z"
    },
    "id": "xrt52ahnt8Gw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 25372\n"
     ]
    }
   ],
   "source": [
    "# if you save your Word2Vec as the variable model, this will \n",
    "# print out the vocabulary size\n",
    "print('Vocab size: {}'.format(len(model_spooky.wv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:39:48.730304Z",
     "start_time": "2020-10-24T04:39:45.451960Z"
    },
    "id": "UUanXgQLt8Gy"
   },
   "outputs": [],
   "source": [
    "# You can save file in txt format, then load later if you wish.\n",
    "model_spooky.wv.save_word2vec_format('embeddings.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGMUTMcmt8G0"
   },
   "source": [
    "### b) Train embedding on YOUR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from u . s .- japa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they told reuter correspondents in asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but some exporters said that while the conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the u . s . has said it will impose 300 mln dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unofficial japanese estimates put the impact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54711</th>\n",
       "      <td>knight - ridder inc &amp; lt ; krn &gt; sets quarterl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54712</th>\n",
       "      <td>technitrol inc &amp; lt ; tnl &gt; sets quarterly qtl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54713</th>\n",
       "      <td>nationwide cellular service inc &amp; lt ; ncel &gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54714</th>\n",
       "      <td>&amp; lt ; a . h . a .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54715</th>\n",
       "      <td>automotive technologies corp &gt; year net shr 43...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54716 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      asian exporters fear damage from u . s .- japa...\n",
       "1      they told reuter correspondents in asian capit...\n",
       "2      but some exporters said that while the conflic...\n",
       "3      the u . s . has said it will impose 300 mln dl...\n",
       "4      unofficial japanese estimates put the impact o...\n",
       "...                                                  ...\n",
       "54711  knight - ridder inc & lt ; krn > sets quarterl...\n",
       "54712  technitrol inc & lt ; tnl > sets quarterly qtl...\n",
       "54713  nationwide cellular service inc & lt ; ncel > ...\n",
       "54714                                 & lt ; a . h . a .\n",
       "54715  automotive technologies corp > year net shr 43...\n",
       "\n",
       "[54716 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "file_ids = reuters.file_ids = reuters.fileids()\n",
    "\n",
    "all_sents = []\n",
    "for file_id in file_ids:\n",
    "    sent_tokens = reuters.sents(file_id)\n",
    "    sentences = [\" \".join(list_of_words).lower() for list_of_words in sent_tokens]\n",
    "    all_sents.extend(sentences)\n",
    "\n",
    "reuters_json = {\"text\": all_sents}\n",
    "df_reuters = pd.DataFrame.from_dict(reuters_json)\n",
    "\n",
    "df_reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30996\n"
     ]
    }
   ],
   "source": [
    "reuters_data = df_reuters.text.apply(nltk.word_tokenize).tolist()\n",
    "model_reuters = Word2Vec(sentences=reuters_data, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n",
    "print('Vocab size: {}'.format(len(model_reuters.wv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"We wouldn't be able to do business,\" said a spokesman for\n",
      "  leading Japanese electronics firm Matsushita Electric\n",
      "  Industrial Co Ltd &lt;MC.T>.\n",
      "      \"If the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
      "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
      "  Capel and Co>.\n",
      "      In Taiwan, businessmen and officials are also worried.\n",
      "      \"We are aware of the seriousness of the U.S. Threat against\n",
      "  Japan because it serves as a warning to us,\" said a senior\n",
      "  Taiwanese trade official who asked not to be named.\n",
      "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the U.S.\n",
      "      The surplus helped swell Taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"We must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of U.S. Products, if we\n",
      "  want to defuse problems from possible U.S. Retaliation,\" said\n",
      "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
      "      A senior official of South Korea's trade promotion\n",
      "  association said the trade dispute between the U.S. And Japan\n",
      "  might also lead to pressure on South Korea, whose chief exports\n",
      "  are similar to those of Japan.\n",
      "      Last year South Korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
      "      In Malaysia, trade officers and businessmen said tough\n",
      "  curbs against Japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  U.S.\n",
      "      In Hong Kong, where newspapers have alleged Japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. But other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further U.S. Pressure to block imports.\n",
      "      \"That is a very short-term view,\" said Lawrence Mills,\n",
      "  director-general of the Federation of Hong Kong Industry.\n",
      "      \"If the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. Much more serious for Hong Kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      The U.S. Last year was Hong Kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      The Australian government is awaiting the outcome of trade\n",
      "  talks between the U.S. And Japan with interest and concern,\n",
      "  Industry Minister John Button said in Canberra last Friday.\n",
      "      \"This kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" Button said.\n",
      "      He said Australia's concerns centred on coal and beef,\n",
      "  Australia's two largest exports to Japan and also significant\n",
      "  U.S. Exports to that country.\n",
      "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
      "  a package of economic measures to boost the Japanese economy.\n",
      "      The measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      They also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite Prime Minister\n",
      "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
      "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
      "  Kuroda, Japan's deputy minister of International Trade and\n",
      "  Industry (MITI), are due to meet in Washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n",
      "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(reuters.raw(file_ids[0]))\n",
    "print(reuters.sents(file_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "https://testanother-codwar.medium.com/sentiment-analysis-on-nltk-reuters-corpus-2feed2a695e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsjzTVFjt8G1"
   },
   "source": [
    "What text-normalization and pre-processing did you do and why? __YOUR ANSWER HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOFmHpH8t8G2"
   },
   "source": [
    "Step 2: Evaluate the differences between the word embeddings\n",
    "----------------------------\n",
    "\n",
    "(make sure to include graphs, figures, and paragraphs with full sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXjy2-OqgvIf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWlWydbrgv4P"
   },
   "source": [
    "## Write down your analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tmrTVDqt8G2"
   },
   "source": [
    "Cite your sources:\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix2On6zat8G2"
   },
   "source": [
    "Step 3: Feedforward Neural Language Model\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZsCKQWDt8G2"
   },
   "source": [
    "### a) First, encode  your text into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T21:39:09.625031Z",
     "start_time": "2020-10-26T21:39:09.009109Z"
    },
    "id": "ec0KKYj0t8G3"
   },
   "outputs": [],
   "source": [
    "# Importing utility functions from Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# The size of the ngram language model you want to train\n",
    "# change as needed for your experiments\n",
    "NGRAM = 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCndArPmt8G5"
   },
   "source": [
    "### b) Next, prepare your sequences from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jG42_9Xt8G6"
   },
   "source": [
    "#### Fixed ngram based sequences "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "HsoPVS8ct8G7"
   },
   "source": [
    "The training samples will be structured in the following format. \n",
    "Depending on which ngram model we choose, there will be (n-1) tokens \n",
    "in the input sequence (X) and we will need to predict the nth token (Y)\n",
    "\n",
    "            X,\t\t\t\t\t\t  y\n",
    "    this,    process               however\n",
    "    process, however               afforded\n",
    "    however, afforded\t           me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T05:21:28.039381Z",
     "start_time": "2020-10-24T05:21:24.941885Z"
    },
    "id": "B_4YqhKTt8G7"
   },
   "outputs": [],
   "source": [
    "def generate_ngram_training_samples(encoded: list[list[int]], ngram:int) -> list[list[int]]:\n",
    "    '''\n",
    "    Takes the encoded data (list of lists) and \n",
    "    generates the training samples out of it.\n",
    "    Parameters:\n",
    "    up to you, we've put in what we used\n",
    "    but you can add/remove as needed\n",
    "    return: \n",
    "    list of lists in the format [[x1, x2, ... , x(n-1), y], ...]\n",
    "    '''\n",
    "    # flattened list comprehension\n",
    "    samples = np.array([np.array(sentence[i:i+ngram]) for sentence in encoded for i in range(len(sentence)-ngram+1)])\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWL6Czlxt8G8"
   },
   "source": [
    "### c) Then, split the sequences into X and y and create a Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport gensim.downloader\\nEMBEDDINGS_SIZE = 100\\nglove_vectors = gensim.downloader.load('glove-twitter-100')\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JUST FOR TESTING PURPOSES SINCE I DONT HAVE WORD EMBEDDINGS TO WORK WITH\n",
    "\"\"\"\n",
    "import gensim.downloader\n",
    "EMBEDDINGS_SIZE = 100\n",
    "glove_vectors = gensim.downloader.load('glove-twitter-100')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T05:22:24.016237Z",
     "start_time": "2020-10-24T05:22:24.011220Z"
    },
    "id": "H6g9g7p6t8G9"
   },
   "outputs": [],
   "source": [
    "from time import time_ns\n",
    "\n",
    "# Note here that the sequences were in the form: \n",
    "# sequence = [x1, x2, ... , x(n-1), y]\n",
    "# We still need to separate it into [[x1, x2, ... , x(n-1)], ...], [y1, y2, ...]\n",
    "\n",
    "# returns X and y using given encoded ngram training samples\n",
    "def split_X_y(samples: list[list[int]]) -> tuple[list[list[int]],list[int]]:\n",
    "    return np.array([l[:-1] for l in samples]), np.array([l[-1] for l in samples])\n",
    "\n",
    "def read_embeddings(tokenizer: Tokenizer, model: KeyedVectors) -> tuple[dict[str,list], dict[int,list]]:\n",
    "    '''Loads and parses embeddings trained in earlier.\n",
    "    Parameters and return values are up to you.\n",
    "    '''\n",
    "    \n",
    "    # you may find generating the following two dicts useful:\n",
    "    # word to embedding : {'the':[0....], ...}\n",
    "    # index to embedding : {1:[0....], ...} \n",
    "    # use your tokenizer's word_index to find the index of\n",
    "    # a given word\n",
    "    word_embeddings = {w:model[w]  if w in model else np.zeros(EMBEDDINGS_SIZE) for w in tokenizer.word_index}\n",
    "    encoded_embeddings = {tokenizer.word_index[w]:word_embeddings[w] for w in word_embeddings}\n",
    "    return word_embeddings, encoded_embeddings\n",
    "\n",
    "lasttime=-1\n",
    "\n",
    "def data_generator(X, y, batch_size: int, tokenizer: Tokenizer, enc_embed:dict) -> tuple[list,list]:\n",
    "    '''\n",
    "    Returns data generator to be used by feed_forward\n",
    "    https://wiki.python.org/moin/Generators\n",
    "    https://realpython.com/introduction-to-python-generators/\n",
    "    \n",
    "    Yields batches of embeddings and labels to go with them.\n",
    "    Use one hot vectors to encode the labels \n",
    "    (see the to_categorical function)\n",
    "    \n",
    "    '''\n",
    "    global lasttime\n",
    "    lasttime = time_ns()\n",
    "    i = 0\n",
    "    for i in range(0,len(y),batch_size):\n",
    "        t1 = time_ns()\n",
    "        next_i = min(len(y), i+batch_size)\n",
    "        # for each sequence in the batch, flatten all word embedding vectors into one vector\n",
    "        embeddings = np.array([np.array([weight for word_index in sequence for weight in enc_embed[word_index]]) for sequence in X[i:next_i]])\n",
    "        labels = to_categorical(y[i:next_i]-1,num_classes=len(tokenizer.word_counts))\n",
    "        t2 = time_ns()\n",
    "        # print(\"elapsed time (ms):\",round((t2-t1)*0.000001,6))\n",
    "        # print(\"overall time (ms):\",round((t1-lasttime)*0.000001,6))\n",
    "        lasttime = time_ns()\n",
    "        yield embeddings, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzfweqz1t8G-"
   },
   "source": [
    "### d) Train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jVjtknkVt8HA"
   },
   "outputs": [],
   "source": [
    "# given lines of text (arraylike) and embeddings (model.wv)\n",
    "def train_model(corpus,embeddings:KeyedVectors):\n",
    "\n",
    "    # Initializing a Tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # encoded = tokenizer.texts_to_sequences([\"Hello, my love, my world.\",\"I love you more than the world itself.\"])\n",
    "    encoded = tokenizer.texts_to_sequences(corpus)\n",
    "    # print(encoded)\n",
    "    VOCAB_SIZE = len(tokenizer.word_counts)\n",
    "    print(VOCAB_SIZE)\n",
    "\n",
    "    ngram_samples = generate_ngram_training_samples(encoded, NGRAM)\n",
    "    print(\"ngram_samples:\",ngram_samples[:4])\n",
    "\n",
    "    X, y = split_X_y(ngram_samples)\n",
    "    print(\"X:\",X)\n",
    "    print(\"y:\",y)\n",
    "\n",
    "    word_embed, enc_embed = read_embeddings(tokenizer,embeddings)\n",
    "    # code to train a feedforward neural language model \n",
    "    # on a set of given word embeddings\n",
    "    # make sure not to just copy + paste to train your two models\n",
    "\n",
    "    num_sequences_per_batch = 64 # this is the batch size\n",
    "    steps_per_epoch = len(ngram_samples)//num_sequences_per_batch  # Number of batches per epoch\n",
    "    train_generator = data_generator(X, y, num_sequences_per_batch, tokenizer, enc_embed)\n",
    "    sample=next(train_generator) # this is how you get data out of generators\n",
    "    print(sample[0].shape, \"; (n-1)*EMBEDDING_SIZE) =\",(NGRAM-1)*EMBEDDINGS_SIZE) # (batch_size, (n-1)*EMBEDDING_SIZE)  (128, 200)\n",
    "    print(sample[1].shape)   # (batch_size, |V|) to_categorical\n",
    "\n",
    "    # Define the model architecture using Keras Sequential API\n",
    "    model = Sequential()\n",
    "    model.add(layer_i := Dense(1000, input_dim=(NGRAM-1)*EMBEDDINGS_SIZE)) \n",
    "    model.add(layer_h1 := Dense(500, activation='relu'))\n",
    "    # model.add(layer_h2 := Dense(100, activation='relu'))\n",
    "    model.add(layer_o := Dense(VOCAB_SIZE)) \n",
    "\n",
    "    # for a multi-class classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    # Start training the model\n",
    "    model.fit(x=train_generator, \n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "eCZ2S5mpt8HA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25943\n",
      "ngram_samples: [[  26 2945  143]\n",
      " [2945  143 1372]\n",
      " [ 143 1372   22]\n",
      " [1372   22   36]]\n",
      "X: [[  26 2945]\n",
      " [2945  143]\n",
      " [ 143 1372]\n",
      " ...\n",
      " [  20  465]\n",
      " [ 465    9]\n",
      " [   9    2]]\n",
      "y: [ 143 1372   22 ...    9    2 5991]\n",
      "overall time (ms): 0.003247\n",
      "(64, 400) ; (n-1)*EMBEDDING_SIZE) = 400\n",
      "(64, 25943)\n",
      "overall time (ms): 49.069719\n",
      "overall time (ms): 371.395961\n",
      "   1/7562 [..............................] - ETA: 56:58 - loss: 11.1240 - accuracy: 0.0000e+00overall time (ms): 108.118867\n",
      "   2/7562 [..............................] - ETA: 17:30 - loss: 11.0048 - accuracy: 0.0000e+00overall time (ms): 130.392857\n",
      "   3/7562 [..............................] - ETA: 18:51 - loss: 11.1328 - accuracy: 0.0052    overall time (ms): 152.273149\n",
      "   4/7562 [..............................] - ETA: 18:52 - loss: 11.0165 - accuracy: 0.0039overall time (ms): 142.088589\n",
      "   5/7562 [..............................] - ETA: 17:59 - loss: 10.9289 - accuracy: 0.0031overall time (ms): 113.052945\n",
      "   6/7562 [..............................] - ETA: 17:31 - loss: 10.9339 - accuracy: 0.0026overall time (ms): 103.86507\n",
      "   7/7562 [..............................] - ETA: 17:12 - loss: 10.8579 - accuracy: 0.0022overall time (ms): 115.226988\n",
      "   8/7562 [..............................] - ETA: 17:03 - loss: 10.7916 - accuracy: 0.0020overall time (ms): 121.494102\n",
      "   9/7562 [..............................] - ETA: 16:51 - loss: 10.8246 - accuracy: 0.0017overall time (ms): 113.905392\n",
      "  10/7562 [..............................] - ETA: 16:41 - loss: 10.7643 - accuracy: 0.0047overall time (ms): 111.700613\n",
      "  11/7562 [..............................] - ETA: 16:38 - loss: 10.7736 - accuracy: 0.0043overall time (ms): 118.670655\n",
      "  12/7562 [..............................] - ETA: 16:32 - loss: 10.8127 - accuracy: 0.0052overall time (ms): 115.766794\n",
      "  13/7562 [..............................] - ETA: 16:33 - loss: 10.8199 - accuracy: 0.0048overall time (ms): 124.264883\n",
      "  14/7562 [..............................] - ETA: 16:29 - loss: 10.7937 - accuracy: 0.0056overall time (ms): 114.837158\n",
      "  15/7562 [..............................] - ETA: 16:26 - loss: 10.8282 - accuracy: 0.0063overall time (ms): 118.291531\n",
      "  16/7562 [..............................] - ETA: 16:23 - loss: 10.9546 - accuracy: 0.0068overall time (ms): 117.563995\n",
      "  17/7562 [..............................] - ETA: 16:22 - loss: 10.9189 - accuracy: 0.0064overall time (ms): 117.803519\n",
      "  18/7562 [..............................] - ETA: 16:18 - loss: 10.9855 - accuracy: 0.0061overall time (ms): 114.505221\n",
      "  19/7562 [..............................] - ETA: 16:15 - loss: 10.9548 - accuracy: 0.0058overall time (ms): 114.149787\n",
      "  20/7562 [..............................] - ETA: 16:13 - loss: 11.0007 - accuracy: 0.0055overall time (ms): 116.123298\n",
      "  21/7562 [..............................] - ETA: 16:10 - loss: 11.0505 - accuracy: 0.0082overall time (ms): 110.89987\n",
      "  22/7562 [..............................] - ETA: 16:09 - loss: 11.1417 - accuracy: 0.0121overall time (ms): 114.510058\n",
      "  23/7562 [..............................] - ETA: 16:08 - loss: 11.2056 - accuracy: 0.0129overall time (ms): 121.325965\n",
      "  24/7562 [..............................] - ETA: 16:08 - loss: 11.2370 - accuracy: 0.0163overall time (ms): 118.072088\n",
      "  25/7562 [..............................] - ETA: 16:08 - loss: 11.2826 - accuracy: 0.0181overall time (ms): 119.650299\n",
      "  26/7562 [..............................] - ETA: 16:06 - loss: 11.3026 - accuracy: 0.0198overall time (ms): 114.181061\n",
      "  27/7562 [..............................] - ETA: 16:03 - loss: 11.3021 - accuracy: 0.0231overall time (ms): 108.323087\n",
      "  28/7562 [..............................] - ETA: 16:04 - loss: 11.3265 - accuracy: 0.0257overall time (ms): 120.208957\n",
      "  29/7562 [..............................] - ETA: 16:02 - loss: 11.3454 - accuracy: 0.0269overall time (ms): 112.377313\n",
      "  30/7562 [..............................] - ETA: 16:01 - loss: 11.3768 - accuracy: 0.0286overall time (ms): 115.147323\n",
      "  31/7562 [..............................] - ETA: 16:01 - loss: 11.3723 - accuracy: 0.0302overall time (ms): 117.53348\n",
      "  32/7562 [..............................] - ETA: 16:00 - loss: 11.3658 - accuracy: 0.0322overall time (ms): 115.379704\n",
      "  33/7562 [..............................] - ETA: 15:59 - loss: 11.3395 - accuracy: 0.0346overall time (ms): 115.669998\n",
      "  34/7562 [..............................] - ETA: 15:59 - loss: 11.3773 - accuracy: 0.0349overall time (ms): 119.945732\n",
      "  35/7562 [..............................] - ETA: 15:59 - loss: 11.4084 - accuracy: 0.0366overall time (ms): 119.394484\n",
      "  36/7562 [..............................] - ETA: 15:59 - loss: 11.3901 - accuracy: 0.0373overall time (ms): 115.049338\n",
      "  37/7562 [..............................] - ETA: 15:58 - loss: 11.3999 - accuracy: 0.0380overall time (ms): 117.120929\n",
      "  38/7562 [..............................] - ETA: 15:58 - loss: 11.4228 - accuracy: 0.0395overall time (ms): 119.487105\n",
      "  39/7562 [..............................] - ETA: 15:58 - loss: 11.4379 - accuracy: 0.0405overall time (ms): 120.111457\n",
      "  40/7562 [..............................] - ETA: 15:59 - loss: 11.4428 - accuracy: 0.0422overall time (ms): 121.403475\n",
      "  41/7562 [..............................] - ETA: 15:58 - loss: 11.4563 - accuracy: 0.0438overall time (ms): 117.706132\n",
      "  42/7562 [..............................] - ETA: 15:58 - loss: 11.4828 - accuracy: 0.0432overall time (ms): 119.031545\n",
      "  43/7562 [..............................] - ETA: 15:58 - loss: 11.4936 - accuracy: 0.0432overall time (ms): 120.80765\n",
      "  44/7562 [..............................] - ETA: 15:59 - loss: 11.5146 - accuracy: 0.0426overall time (ms): 123.31012\n",
      "  45/7562 [..............................] - ETA: 15:58 - loss: 11.5174 - accuracy: 0.0427overall time (ms): 113.811165\n",
      "  46/7562 [..............................] - ETA: 15:58 - loss: 11.5236 - accuracy: 0.0442overall time (ms): 123.088295\n",
      "  47/7562 [..............................] - ETA: 15:58 - loss: 11.5214 - accuracy: 0.0442overall time (ms): 120.038733\n",
      "  48/7562 [..............................] - ETA: 15:59 - loss: 11.5446 - accuracy: 0.0443overall time (ms): 124.961826\n",
      "  49/7562 [..............................] - ETA: 16:02 - loss: 11.5584 - accuracy: 0.0450overall time (ms): 138.24476\n",
      "  50/7562 [..............................] - ETA: 16:02 - loss: 11.5722 - accuracy: 0.0444overall time (ms): 122.427926\n",
      "  51/7562 [..............................] - ETA: 16:06 - loss: 11.5875 - accuracy: 0.0450overall time (ms): 145.942314\n",
      "  52/7562 [..............................] - ETA: 16:05 - loss: 11.6012 - accuracy: 0.0454overall time (ms): 114.661347\n",
      "  53/7562 [..............................] - ETA: 16:05 - loss: 11.6065 - accuracy: 0.0454overall time (ms): 113.006491\n",
      "  54/7562 [..............................] - ETA: 16:05 - loss: 11.6179 - accuracy: 0.0460overall time (ms): 122.89259\n",
      "  55/7562 [..............................] - ETA: 16:03 - loss: 11.6258 - accuracy: 0.0466overall time (ms): 111.637887\n",
      "  56/7562 [..............................] - ETA: 16:02 - loss: 11.6339 - accuracy: 0.0469overall time (ms): 110.371072\n",
      "  57/7562 [..............................] - ETA: 16:03 - loss: 11.6407 - accuracy: 0.0466overall time (ms): 125.842787\n",
      "  58/7562 [..............................] - ETA: 16:02 - loss: 11.6431 - accuracy: 0.0474overall time (ms): 116.8599\n",
      "  59/7562 [..............................] - ETA: 16:02 - loss: 11.6460 - accuracy: 0.0477overall time (ms): 119.136261\n",
      "  60/7562 [..............................] - ETA: 16:04 - loss: 11.6615 - accuracy: 0.0479overall time (ms): 131.527852\n",
      "  61/7562 [..............................] - ETA: 16:03 - loss: 11.6673 - accuracy: 0.0482overall time (ms): 117.027711\n",
      "  62/7562 [..............................] - ETA: 16:03 - loss: 11.6512 - accuracy: 0.0486overall time (ms): 121.601957\n",
      "  63/7562 [..............................] - ETA: 16:03 - loss: 11.6426 - accuracy: 0.0486overall time (ms): 122.485283\n",
      "  64/7562 [..............................] - ETA: 16:02 - loss: 11.6351 - accuracy: 0.0488overall time (ms): 114.050659\n",
      "  65/7562 [..............................] - ETA: 16:02 - loss: 11.6245 - accuracy: 0.0490overall time (ms): 112.364749\n",
      "  66/7562 [..............................] - ETA: 16:01 - loss: 11.6195 - accuracy: 0.0497overall time (ms): 118.21126\n",
      "  67/7562 [..............................] - ETA: 16:01 - loss: 11.6092 - accuracy: 0.0504overall time (ms): 113.492282\n",
      "  68/7562 [..............................] - ETA: 16:00 - loss: 11.6146 - accuracy: 0.0510overall time (ms): 110.542242\n",
      "  69/7562 [..............................] - ETA: 15:59 - loss: 11.5997 - accuracy: 0.0505overall time (ms): 112.644674\n",
      "  70/7562 [..............................] - ETA: 15:58 - loss: 11.5893 - accuracy: 0.0507overall time (ms): 115.097215\n",
      "  71/7562 [..............................] - ETA: 15:57 - loss: 11.5679 - accuracy: 0.0508overall time (ms): 110.647617\n",
      "  72/7562 [..............................] - ETA: 15:57 - loss: 11.5603 - accuracy: 0.0506overall time (ms): 122.126841\n",
      "  73/7562 [..............................] - ETA: 15:56 - loss: 11.5624 - accuracy: 0.0507overall time (ms): 111.629956\n",
      "  74/7562 [..............................] - ETA: 15:55 - loss: 11.5651 - accuracy: 0.0507overall time (ms): 111.65979\n",
      "  75/7562 [..............................] - ETA: 15:55 - loss: 11.5566 - accuracy: 0.0504overall time (ms): 115.808785\n",
      "  76/7562 [..............................] - ETA: 15:54 - loss: 11.5644 - accuracy: 0.0504overall time (ms): 111.765798\n",
      "  77/7562 [..............................] - ETA: 15:53 - loss: 11.5586 - accuracy: 0.0505overall time (ms): 108.715926\n",
      "  78/7562 [..............................] - ETA: 15:52 - loss: 11.5434 - accuracy: 0.0507overall time (ms): 117.383804\n",
      "  79/7562 [..............................] - ETA: 15:52 - loss: 11.5553 - accuracy: 0.0512overall time (ms): 113.632757\n",
      "  80/7562 [..............................] - ETA: 15:52 - loss: 11.5578 - accuracy: 0.0521overall time (ms): 116.504188\n",
      "  81/7562 [..............................] - ETA: 15:51 - loss: 11.5640 - accuracy: 0.0527overall time (ms): 108.053153\n",
      "  82/7562 [..............................] - ETA: 15:50 - loss: 11.5495 - accuracy: 0.0524overall time (ms): 114.700897\n",
      "  83/7562 [..............................] - ETA: 15:50 - loss: 11.5374 - accuracy: 0.0523overall time (ms): 115.523172\n",
      "  84/7562 [..............................] - ETA: 15:50 - loss: 11.5385 - accuracy: 0.0528overall time (ms): 116.950448\n",
      "  85/7562 [..............................] - ETA: 15:48 - loss: 11.5365 - accuracy: 0.0533overall time (ms): 107.138976\n",
      "  86/7562 [..............................] - ETA: 15:48 - loss: 11.5163 - accuracy: 0.0536overall time (ms): 112.177725\n",
      "  87/7562 [..............................] - ETA: 15:47 - loss: 11.5205 - accuracy: 0.0542overall time (ms): 117.198424\n",
      "  88/7562 [..............................] - ETA: 15:47 - loss: 11.5276 - accuracy: 0.0540overall time (ms): 118.035897\n",
      "  89/7562 [..............................] - ETA: 15:47 - loss: 11.5263 - accuracy: 0.0550overall time (ms): 112.736293\n",
      "  90/7562 [..............................] - ETA: 15:46 - loss: 11.5258 - accuracy: 0.0550overall time (ms): 113.366612\n",
      "  91/7562 [..............................] - ETA: 15:46 - loss: 11.5312 - accuracy: 0.0555overall time (ms): 113.306245\n",
      "  92/7562 [..............................] - ETA: 15:46 - loss: 11.5229 - accuracy: 0.0557overall time (ms): 121.756383\n",
      "  93/7562 [..............................] - ETA: 15:47 - loss: 11.5207 - accuracy: 0.0563overall time (ms): 136.137534\n",
      "  94/7562 [..............................] - ETA: 15:48 - loss: 11.5240 - accuracy: 0.0562overall time (ms): 126.560442\n",
      "  95/7562 [..............................] - ETA: 15:48 - loss: 11.5398 - accuracy: 0.0558overall time (ms): 124.308507\n",
      "  96/7562 [..............................] - ETA: 15:48 - loss: 11.5227 - accuracy: 0.0553overall time (ms): 120.584176\n",
      "  97/7562 [..............................] - ETA: 15:48 - loss: 11.5289 - accuracy: 0.0559overall time (ms): 124.918297\n",
      "  98/7562 [..............................] - ETA: 15:49 - loss: 11.5386 - accuracy: 0.0555overall time (ms): 128.624366\n",
      "  99/7562 [..............................] - ETA: 15:49 - loss: 11.5478 - accuracy: 0.0557overall time (ms): 119.897526\n",
      " 100/7562 [..............................] - ETA: 15:49 - loss: 11.5505 - accuracy: 0.0556overall time (ms): 115.936037\n",
      " 101/7562 [..............................] - ETA: 15:49 - loss: 11.5582 - accuracy: 0.0554overall time (ms): 118.145854\n",
      " 102/7562 [..............................] - ETA: 15:49 - loss: 11.5525 - accuracy: 0.0553overall time (ms): 121.734823\n",
      " 103/7562 [..............................] - ETA: 15:49 - loss: 11.5511 - accuracy: 0.0555overall time (ms): 117.145851\n",
      " 104/7562 [..............................] - ETA: 15:48 - loss: 11.5581 - accuracy: 0.0557overall time (ms): 112.15767\n",
      " 105/7562 [..............................] - ETA: 15:48 - loss: 11.5618 - accuracy: 0.0554overall time (ms): 117.49128\n",
      " 106/7562 [..............................] - ETA: 15:48 - loss: 11.5630 - accuracy: 0.0554overall time (ms): 118.224793\n",
      " 107/7562 [..............................] - ETA: 15:47 - loss: 11.5760 - accuracy: 0.0549overall time (ms): 115.417948\n",
      " 108/7562 [..............................] - ETA: 15:48 - loss: 11.5798 - accuracy: 0.0553overall time (ms): 127.804317\n",
      " 109/7562 [..............................] - ETA: 15:48 - loss: 11.5818 - accuracy: 0.0558overall time (ms): 126.520914\n",
      " 110/7562 [..............................] - ETA: 15:49 - loss: 11.5932 - accuracy: 0.0558overall time (ms): 121.15615\n",
      " 111/7562 [..............................] - ETA: 15:48 - loss: 11.5865 - accuracy: 0.0562overall time (ms): 107.814041\n",
      " 112/7562 [..............................] - ETA: 15:48 - loss: 11.5912 - accuracy: 0.0561overall time (ms): 117.849094\n",
      " 113/7562 [..............................] - ETA: 15:48 - loss: 11.6024 - accuracy: 0.0563overall time (ms): 124.147515\n",
      " 114/7562 [..............................] - ETA: 15:48 - loss: 11.6074 - accuracy: 0.0562overall time (ms): 126.013733\n",
      " 115/7562 [..............................] - ETA: 15:48 - loss: 11.6067 - accuracy: 0.0565overall time (ms): 122.289701\n",
      " 116/7562 [..............................] - ETA: 15:48 - loss: 11.6114 - accuracy: 0.0563overall time (ms): 120.316737\n",
      " 117/7562 [..............................] - ETA: 15:48 - loss: 11.6126 - accuracy: 0.0561overall time (ms): 114.579083\n",
      " 118/7562 [..............................] - ETA: 15:47 - loss: 11.6101 - accuracy: 0.0564overall time (ms): 110.789677\n",
      " 119/7562 [..............................] - ETA: 15:47 - loss: 11.6216 - accuracy: 0.0562overall time (ms): 117.261872\n",
      " 120/7562 [..............................] - ETA: 15:47 - loss: 11.6245 - accuracy: 0.0566overall time (ms): 111.074124\n",
      " 121/7562 [..............................] - ETA: 15:47 - loss: 11.6354 - accuracy: 0.0568overall time (ms): 122.955023\n",
      " 122/7562 [..............................] - ETA: 15:47 - loss: 11.6359 - accuracy: 0.0567overall time (ms): 114.754389\n",
      " 123/7562 [..............................] - ETA: 15:46 - loss: 11.6389 - accuracy: 0.0568overall time (ms): 114.555415\n",
      " 124/7562 [..............................] - ETA: 15:46 - loss: 11.6461 - accuracy: 0.0567overall time (ms): 113.904385\n",
      " 125/7562 [..............................] - ETA: 15:46 - loss: 11.6459 - accuracy: 0.0570overall time (ms): 125.341537\n",
      " 126/7562 [..............................] - ETA: 15:46 - loss: 11.6610 - accuracy: 0.0568overall time (ms): 116.458285\n",
      " 127/7562 [..............................] - ETA: 15:46 - loss: 11.6587 - accuracy: 0.0570overall time (ms): 118.072068\n",
      " 128/7562 [..............................] - ETA: 15:47 - loss: 11.6663 - accuracy: 0.0570overall time (ms): 131.667542\n",
      " 129/7562 [..............................] - ETA: 15:46 - loss: 11.6756 - accuracy: 0.0569overall time (ms): 113.735713\n",
      " 130/7562 [..............................] - ETA: 15:46 - loss: 11.6761 - accuracy: 0.0567overall time (ms): 121.428495\n",
      " 131/7562 [..............................] - ETA: 15:47 - loss: 11.6750 - accuracy: 0.0567overall time (ms): 136.59315\n",
      " 132/7562 [..............................] - ETA: 15:48 - loss: 11.6808 - accuracy: 0.0567overall time (ms): 126.330976\n",
      " 133/7562 [..............................] - ETA: 15:48 - loss: 11.6848 - accuracy: 0.0565overall time (ms): 124.236201\n",
      " 134/7562 [..............................] - ETA: 15:48 - loss: 11.6811 - accuracy: 0.0567overall time (ms): 121.080856\n",
      " 135/7562 [..............................] - ETA: 15:48 - loss: 11.6788 - accuracy: 0.0568overall time (ms): 120.32469\n",
      " 136/7562 [..............................] - ETA: 15:48 - loss: 11.6820 - accuracy: 0.0569overall time (ms): 123.546949\n",
      " 137/7562 [..............................] - ETA: 15:48 - loss: 11.6914 - accuracy: 0.0566overall time (ms): 118.31434\n",
      " 138/7562 [..............................] - ETA: 15:48 - loss: 11.6867 - accuracy: 0.0566overall time (ms): 113.563579\n",
      " 139/7562 [..............................] - ETA: 15:47 - loss: 11.6871 - accuracy: 0.0569overall time (ms): 111.382891\n",
      " 140/7562 [..............................] - ETA: 15:47 - loss: 11.6862 - accuracy: 0.0568overall time (ms): 119.308779\n",
      " 141/7562 [..............................] - ETA: 15:47 - loss: 11.6855 - accuracy: 0.0567overall time (ms): 112.505146\n",
      " 142/7562 [..............................] - ETA: 15:46 - loss: 11.6732 - accuracy: 0.0568overall time (ms): 111.233859\n",
      " 143/7562 [..............................] - ETA: 15:46 - loss: 11.6756 - accuracy: 0.0565overall time (ms): 114.958016\n",
      " 144/7562 [..............................] - ETA: 15:46 - loss: 11.6731 - accuracy: 0.0570overall time (ms): 115.740918\n",
      " 145/7562 [..............................] - ETA: 15:45 - loss: 11.6688 - accuracy: 0.0571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(spooky_df[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m],model_spooky\u001b[39m.\u001b[39;49mwv)  \n",
      "Cell \u001b[0;32mIn[50], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(corpus, embeddings)\u001b[0m\n\u001b[1;32m     40\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     41\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     45\u001b[0m \u001b[39m# Start training the model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_generator, \n\u001b[1;32m     47\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m     48\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1641\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1639\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1640\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1641\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1642\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m         ):\n\u001b[1;32m   1649\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1371\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1370\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1371\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1372\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1373\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1374\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[1;32m   1376\u001b[0m )\n\u001b[1;32m   1378\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:639\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    640\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    641\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:727\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \n\u001b[1;32m    720\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 727\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[1;32m    728\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:706\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    704\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    705\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    709\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    710\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[1;32m    712\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[1;32m    713\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    714\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:696\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[1;32m    695\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m--> 696\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[1;32m    698\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[1;32m    699\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:525\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m    524\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m    526\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[1;32m    527\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m    528\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(spooky_df[\"text\"],model_spooky.wv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(df_reuters[\"text\"],model_reuters.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QwRhKYwt8HA"
   },
   "source": [
    "### e) Generate Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:13:54.425934Z",
     "start_time": "2020-10-24T04:13:54.418616Z"
    },
    "id": "ewR5ueOJt8HB"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model: Sequential, \n",
    "                 tokenizer: Tokenizer, \n",
    "                 seed: list, \n",
    "                 n_words: int):\n",
    "    '''\n",
    "    Parameters:\n",
    "        model: your neural network\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        seed: [w1, w2, w(n-1)]\n",
    "        n_words: generate a sentence of length n_words\n",
    "    Returns: string sentence\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T04:14:13.123529Z",
     "start_time": "2020-10-24T04:14:13.000264Z"
    },
    "id": "XZ9fShSyt8HB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w68JVS2jt8HB"
   },
   "source": [
    "### f) Compare your generated sentences\n",
    "\n",
    "You may find it useful to run your HW 2 code on one of the datasets (or a subset of the dataset) that you used for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE4dcQdut8HC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yet5p8N1t8HC"
   },
   "source": [
    "Sources Cited\n",
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- https://pyimagesearch.com/2021/05/06/implementing-feedforward-neural-networks-with-keras-and-tensorflow/\n",
    "- https://keras.io/api/layers/core_layers/dense/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wordembeddings_starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
